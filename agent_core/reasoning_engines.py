"""
Los 3 motores de razonamiento de M.A.R.T.I.N.
"""
from typing import Dict, Any, Optional
import os
from datetime import datetime

# Por ahora usamos respuestas simuladas para no depender de APIs externas
# En producci√≥n, descomentar las importaciones de LangChain/OpenAI

class ReasoningEngines:
    """
    Contiene los 3 modos de razonamiento de M.A.R.T.I.N.
    Cada modo tiene un comportamiento diferente seg√∫n el contexto.
    """
    
    def __init__(self, use_llm: bool = False):
        """
        Args:
            use_llm: Si True, usa LLM real. Si False, usa respuestas simuladas.
        """
        self.use_llm = use_llm
        
        if use_llm:
            try:
                from langchain.chat_models import ChatOpenAI
                self.llm = ChatOpenAI(
                    model="gpt-4",
                    temperature=0,
                    api_key=os.getenv("OPENAI_API_KEY")
                )
            except ImportError:
                print("‚ö†Ô∏è LangChain no instalado. Usando modo simulado.")
                self.use_llm = False
                self.llm = None
        else:
            self.llm = None
    
    def passive_reasoning(self, task: str, context: Dict = None) -> Dict[str, Any]:
        """
        MODO PASIVO: Genera plan pero NO ejecuta
        
        Comportamiento:
        1. Analiza la tarea del usuario
        2. Genera un plan detallado
        3. Explica qu√© har√°
        4. ESPERA confirmaci√≥n del usuario
        """
        
        if context is None:
            context = {}
        
        if self.use_llm and self.llm:
            # Usar LLM real
            from langchain.prompts import PromptTemplate
            
            prompt = PromptTemplate(
                input_variables=["task", "context"],
                template=self._get_passive_prompt_template()
            )
            
            response = self.llm.predict(
                prompt.format(
                    task=task,
                    context=str(context) if context else "No hay contexto adicional"
                )
            )
        else:
            # Respuesta simulada para testing
            response = self._generate_passive_response_mock(task, context)
        
        return {
            "mode": "PASSIVE",
            "status": "awaiting_confirmation",
            "plan": response,
            "message": f"üìã MODO PASIVO ACTIVADO\n\n{response}",
            "requires_user_action": True,
            "timestamp": datetime.now().isoformat()
        }
    
    def direct_reasoning(self, task: str, context: Dict = None) -> Dict[str, Any]:
        """
        MODO DIRECTO: Genera plan Y ejecuta autom√°ticamente
        
        Comportamiento:
        1. Analiza la tarea
        2. Genera plan de acci√≥n
        3. EJECUTA sin preguntar
        4. Reporta resultados
        5. Explica su razonamiento
        """
        
        if context is None:
            context = {}
        
        if self.use_llm and self.llm:
            # Usar LLM real
            from langchain.prompts import PromptTemplate
            
            prompt = PromptTemplate(
                input_variables=["task"],
                template=self._get_direct_prompt_template()
            )
            
            response = self.llm.predict(prompt.format(task=task))
        else:
            # Respuesta simulada para testing
            response = self._generate_direct_response_mock(task, context)
        
        return {
            "mode": "DIRECT",
            "status": "executed",
            "results": response,
            "message": f"‚ö° MODO DIRECTO - Ejecutado autom√°ticamente\n\n{response}",
            "requires_user_action": False,
            "reasoning_visible": True,
            "timestamp": datetime.now().isoformat()
        }
    
    def safe_reasoning(self, task: str, context: Dict = None) -> Dict[str, Any]:
        """
        MODO SEGURO: Genera plan, AUTO-VALIDA, luego decide
        
        Comportamiento:
        1. Analiza la tarea
        2. Genera plan de acci√≥n
        3. SE AUTO-CRITICA (validaci√≥n de riesgos)
        4. Si pasa validaci√≥n ‚Üí ejecuta con precauciones
        5. Si NO pasa ‚Üí sugiere alternativa segura y pide confirmaci√≥n
        """
        
        if context is None:
            context = {}
        
        # Generar plan inicial
        plan = self._generate_initial_plan(task, context)
        
        # Auto-validaci√≥n del plan
        validation_result = self._validate_plan_safety(task, plan, context)
        
        # Decidir basado en validaci√≥n
        if validation_result['is_safe']:
            # Plan aprobado - ejecutar con precauciones
            return {
                "mode": "SAFE",
                "status": "approved_and_executed",
                "validation_passed": True,
                "plan": plan,
                "validation_report": validation_result['report'],
                "precautions": validation_result['precautions'],
                "results": f"[Ejecutado con precauciones: {', '.join(validation_result['precautions'])}]",
                "message": f"üõ°Ô∏è MODO SEGURO - Validado y ejecutado\n\n{validation_result['report']}",
                "requires_user_action": False,
                "timestamp": datetime.now().isoformat()
            }
        else:
            # Plan rechazado - bloquear y sugerir alternativa
            return {
                "mode": "SAFE",
                "status": "blocked",
                "validation_failed": True,
                "original_plan": plan,
                "validation_report": validation_result['report'],
                "risks_identified": validation_result['risks'],
                "alternative_suggestion": validation_result['alternative'],
                "message": f"üõ°Ô∏è MODO SEGURO - ACCI√ìN BLOQUEADA\n\n{validation_result['report']}",
                "requires_user_action": True,
                "timestamp": datetime.now().isoformat()
            }
    
    # ========== M√©todos auxiliares ==========
    
    def _get_passive_prompt_template(self) -> str:
        """Retorna el template del prompt para modo pasivo"""
        return """
Eres M.A.R.T.I.N., un agente de IA en MODO PASIVO.

En este modo eres consultivo y colaborativo. Tu objetivo es:
1. Entender profundamente lo que el usuario necesita
2. Proponer un plan detallado y bien pensado
3. Explicar las opciones disponibles
4. ESPERAR confirmaci√≥n antes de proceder

Tarea del usuario: {task}
Contexto: {context}

Genera una respuesta estructurada con:

## üìã MI AN√ÅLISIS
[Explica c√≥mo entiendes la tarea y qu√© objetivos detectas]

## üéØ PLAN PROPUESTO
[Plan paso a paso con timing estimado]

Paso 1: [Descripci√≥n] (Tiempo: X minutos)
Paso 2: [Descripci√≥n] (Tiempo: Y minutos)
...

## ‚ö†Ô∏è CONSIDERACIONES IMPORTANTES
- [Punto clave 1]
- [Punto clave 2]
- [Riesgos potenciales]

## ü§î PREGUNTAS PARA TI
1. [Pregunta para clarificar]
2. [Pregunta opcional]

¬øTe parece bien este plan? ¬øQuieres que ajuste algo antes de empezar?
"""
    
    def _get_direct_prompt_template(self) -> str:
        """Retorna el template del prompt para modo directo"""
        return """
Eres M.A.R.T.I.N. en MODO DIRECTO - un agente aut√≥nomo y eficiente.

En este modo act√∫as con confianza y autonom√≠a. Tu objetivo es:
1. Analizar r√°pidamente qu√© se necesita hacer
2. Ejecutar directamente sin preguntar
3. Reportar resultados con claridad
4. Explicar tu razonamiento DESPU√âS de ejecutar

Tarea: {task}

Genera una respuesta que muestre:

## ‚ö° EJECUTADO
[Describe qu√© acciones tomaste]

## üìä RESULTADOS
[Presenta los resultados obtenidos de forma clara]

## üß† MI RAZONAMIENTO
[Explica por qu√© tomaste estas decisiones espec√≠ficas]
"""
    
    def _generate_passive_response_mock(self, task: str, context: Dict) -> str:
        """Genera respuesta simulada para modo pasivo"""
        return f"""
## üìã MI AN√ÅLISIS
He analizado tu solicitud: "{task[:100]}..." 
Entiendo que necesitas ayuda con tareas de compliance y preparaci√≥n para certificaci√≥n.

## üéØ PLAN PROPUESTO

**Fase 1: Evaluaci√≥n inicial** (2 horas)
- Paso 1: Auditar tu infraestructura actual (45 min)
- Paso 2: Identificar gaps cr√≠ticos de compliance (45 min)
- Paso 3: Priorizar por impacto y urgencia (30 min)

**Fase 2: Implementaci√≥n** (2 semanas)
- Paso 4: Generar pol√≠ticas faltantes (3 d√≠as)
- Paso 5: Implementar controles t√©cnicos (1 semana)
- Paso 6: Documentar procedimientos (4 d√≠as)

**Fase 3: Validaci√≥n** (1 semana)
- Paso 7: Recopilar evidencia (3 d√≠as)
- Paso 8: Pre-auditor√≠a interna (2 d√≠as)
- Paso 9: Correcciones finales (2 d√≠as)

## ‚ö†Ô∏è CONSIDERACIONES IMPORTANTES
- Este plan asume una organizaci√≥n de 20-50 empleados
- Requiere dedicaci√≥n del equipo t√©cnico (~4h/semana)
- Los tiempos pueden variar seg√∫n la complejidad actual
- Recomiendo empezar por los gaps cr√≠ticos primero

## ü§î PREGUNTAS PARA TI
1. ¬øCu√°l es el tama√±o actual de tu organizaci√≥n?
2. ¬øTienes alguna fecha l√≠mite para la certificaci√≥n?
3. ¬øPrefieres empezar con SOC 2 o ISO 27001?

¬øTe parece bien este plan? ¬øQuieres que ajuste algo antes de empezar?"""
    
    def _generate_direct_response_mock(self, task: str, context: Dict) -> str:
        """Genera respuesta simulada para modo directo"""
        return f"""
## ‚ö° EJECUTADO
He ejecutado autom√°ticamente las siguientes acciones:
1. Analizado los requisitos de "{task[:50]}..."
2. Generado la documentaci√≥n solicitada
3. Aplicado mejores pr√°cticas de la industria

## üìä RESULTADOS

**Pol√≠tica generada:** Pol√≠tica de Contrase√±as seg√∫n ISO 27001

### Requisitos m√≠nimos:
- Longitud: 12 caracteres m√≠nimo
- Complejidad: May√∫sculas, min√∫sculas, n√∫meros y s√≠mbolos
- Rotaci√≥n: Cada 90 d√≠as
- Historia: No reusar √∫ltimas 12 contrase√±as
- MFA: Obligatorio para cuentas administrativas

### Implementaci√≥n:
- Aplicar en Active Directory/LDAP
- Configurar en aplicaciones cloud
- Documentar excepciones autorizadas

### Medici√≥n y cumplimiento:
- Auditor√≠as trimestrales
- Reporte mensual de cumplimiento
- Capacitaci√≥n anual obligatoria

## üß† MI RAZONAMIENTO
Tom√© estas decisiones porque:
1. ISO 27001 requiere controles espec√≠ficos de acceso (A.9.4.3)
2. 12 caracteres es el m√≠nimo actual recomendado por NIST
3. MFA es cr√≠tico para cuentas privilegiadas
4. La rotaci√≥n de 90 d√≠as balancea seguridad y usabilidad

Esta pol√≠tica cumple con los est√°ndares y es pr√°ctica para implementar."""
    
    def _generate_initial_plan(self, task: str, context: Dict) -> str:
        """Genera un plan inicial para validaci√≥n"""
        return f"""
Plan de acci√≥n para: {task}
1. Identificar recursos afectados
2. Evaluar impacto de la operaci√≥n
3. Ejecutar cambios solicitados
4. Verificar resultados
5. Documentar acciones tomadas"""
    
    def _validate_plan_safety(self, task: str, plan: str, context: Dict) -> Dict[str, Any]:
        """
        Valida la seguridad del plan (auto-cr√≠tica)
        Retorna diccionario con resultado de validaci√≥n
        """
        task_lower = task.lower()
        
        # Lista de indicadores de alto riesgo
        high_risk_indicators = [
            'delete', 'remove', 'destroy', 'disable', 'drop',
            'eliminar', 'borrar', 'deshabilitar', 'destruir'
        ]
        
        critical_resources = [
            'admin', 'production', 'database', 'payment', 'auth',
            'password', 'credential', 'secret', 'mfa', '2fa'
        ]
        
        # Detectar riesgos
        risks = []
        risk_level = "BAJO"
        
        for indicator in high_risk_indicators:
            if indicator in task_lower:
                risks.append(f"Operaci√≥n destructiva detectada: '{indicator}'")
                risk_level = "ALTO"
        
        for resource in critical_resources:
            if resource in task_lower:
                risks.append(f"Recurso cr√≠tico afectado: '{resource}'")
                if risk_level != "ALTO":
                    risk_level = "MEDIO"
        
        # Si es producci√≥n, aumentar nivel de riesgo
        if context.get('environment') == 'production':
            risks.append("Operaci√≥n en ambiente de PRODUCCI√ìN")
            risk_level = "CR√çTICO"
        
        # Determinar si es seguro proceder
        is_safe = risk_level in ["BAJO", "MEDIO"]
        
        if is_safe:
            # Plan aprobado con precauciones
            precautions = []
            if risk_level == "MEDIO":
                precautions = [
                    "Crear backup antes de proceder",
                    "Ejecutar en horario de bajo impacto",
                    "Tener plan de rollback preparado"
                ]
            else:
                precautions = ["Monitorear resultados", "Documentar cambios"]
            
            report = f"""
## üîç AN√ÅLISIS DE SEGURIDAD COMPLETADO

**Nivel de riesgo:** {risk_level}
**Decisi√≥n:** ‚úÖ APROBADO PARA EJECUCI√ìN

### Plan validado:
{plan}

### Precauciones a aplicar:
{chr(10).join(f'- {p}' for p in precautions)}

### Factores evaluados:
- Reversibilidad: S√ç
- Impacto en usuarios: M√çNIMO
- Riesgo de p√©rdida de datos: BAJO

Procedo con la ejecuci√≥n aplicando las precauciones listadas."""
            
            return {
                'is_safe': True,
                'risk_level': risk_level,
                'risks': risks,
                'precautions': precautions,
                'report': report,
                'alternative': None
            }
        else:
            # Plan rechazado - muy riesgoso
            alternative = self._generate_safe_alternative(task)
            
            report = f"""
## üîç AN√ÅLISIS DE SEGURIDAD - CR√çTICO

**Nivel de riesgo:** ‚ö†Ô∏è {risk_level}
**Decisi√≥n:** ‚ùå ACCI√ìN BLOQUEADA

### Riesgos identificados:
{chr(10).join(f'- {r}' for r in risks)}

### Plan original (RECHAZADO):
{plan}

### Por qu√© fue bloqueado:
1. La acci√≥n podr√≠a causar p√©rdida de datos o acceso
2. Impacto potencial en sistemas cr√≠ticos
3. Dificultad o imposibilidad de reversi√≥n
4. Violaci√≥n potencial de pol√≠ticas de seguridad

### üîÑ ALTERNATIVA SEGURA SUGERIDA:
{alternative}

### Recomendaci√≥n:
Revisa la alternativa propuesta o consulta con el equipo de seguridad antes de proceder.

¬øDeseas proceder con la alternativa segura propuesta?"""
            
            return {
                'is_safe': False,
                'risk_level': risk_level,
                'risks': risks,
                'precautions': [],
                'report': report,
                'alternative': alternative
            }
    
    def _generate_safe_alternative(self, task: str) -> str:
        """Genera una alternativa m√°s segura para una tarea riesgosa"""
        task_lower = task.lower()
        
        if 'deshabilitar' in task_lower or 'disable' in task_lower:
            if 'mfa' in task_lower or '2fa' in task_lower or 'admin' in task_lower:
                return """
1. En lugar de deshabilitar MFA completamente:
   - Genera c√≥digos de respaldo temporales
   - Configura un m√©todo alternativo de MFA (SMS, app authenticator)
   - Crea una cuenta administrativa temporal con permisos limitados
   
2. Si el usuario est√° bloqueado:
   - Resetea el MFA manteniendo la protecci√≥n activa
   - Usa el proceso de recuperaci√≥n est√°ndar
   - Contacta al usuario para verificaci√≥n de identidad"""
        
        elif 'delete' in task_lower or 'eliminar' in task_lower or 'borrar' in task_lower:
            return """
1. En lugar de eliminar permanentemente:
   - Archivar los recursos en lugar de eliminarlos
   - Hacer un backup completo antes de cualquier eliminaci√≥n
   - Marcar para eliminaci√≥n y aplicar despu√©s de per√≠odo de gracia
   
2. Para limpieza segura:
   - Eliminar en ambiente de desarrollo primero
   - Validar con el equipo antes de proceder
   - Documentar raz√≥n y obtener aprobaci√≥n escrita"""
        
        else:
            return """
1. Enfoque m√°s seguro:
   - Ejecutar primero en ambiente de desarrollo/staging
   - Implementar cambios gradualmente
   - Crear punto de restauraci√≥n antes de proceder
   
2. Validaci√≥n adicional:
   - Revisar con el equipo de seguridad
   - Documentar el cambio en el sistema de tickets
   - Programar ventana de mantenimiento si es necesario"""