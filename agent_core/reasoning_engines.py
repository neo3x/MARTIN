"""
Los 3 motores de razonamiento de M.A.R.T.I.N.
"""
from typing import Dict, Any
import os

class ReasoningEngines:
    """
    Contiene los 3 modos de razonamiento de M.A.R.T.I.N.
    """
    
    def __init__(self, use_llm: bool = False):
        """
        Args:
            use_llm: Si True, usa LLM real. Si False, genera respuestas simuladas.
        """
        self.use_llm = use_llm
        self.llm = None
        
        if self.use_llm:
            try:
                from langchain.chat_models import ChatOpenAI
                api_key = os.getenv("OPENAI_API_KEY")
                if api_key:
                    self.llm = ChatOpenAI(
                        model="gpt-4",
                        temperature=0,
                        api_key=api_key
                    )
                else:
                    print("‚ö†Ô∏è OPENAI_API_KEY no configurada. Usando modo simulado.")
                    self.use_llm = False
            except ImportError:
                print("‚ö†Ô∏è langchain no instalado. Usando modo simulado.")
                self.use_llm = False
    
    def passive_reasoning(self, task: str, context: Dict = None) -> Dict[str, Any]:
        """
        MODO PASIVO: Genera plan pero NO ejecuta
        
        Comportamiento:
        1. Analiza la tarea
        2. Genera un plan detallado
        3. Explica qu√© har√°
        4. ESPERA confirmaci√≥n del usuario
        """
        
        if self.use_llm and self.llm:
            # Usar LLM real
            prompt = f"""
Eres M.A.R.T.I.N., un agente de IA en MODO PASIVO.

En este modo eres consultivo y colaborativo. Tu objetivo es:
1. Entender profundamente lo que el usuario necesita
2. Proponer un plan de acci√≥n detallado
3. Explicar las opciones disponibles
4. ESPERAR confirmaci√≥n antes de proceder

Tarea del usuario: {task}
Contexto: {context if context else "No hay contexto adicional"}

Genera una respuesta estructurada con:

## üìã MI AN√ÅLISIS
[Explica c√≥mo entiendes la tarea y qu√© objetivos detectas]

## üéØ PLAN PROPUESTO
[Plan paso a paso con timing estimado]

Paso 1: [Descripci√≥n] (Tiempo: X minutos)
Paso 2: [Descripci√≥n] (Tiempo: Y minutos)
...

## ‚ö†Ô∏è CONSIDERACIONES IMPORTANTES
- [Punto clave 1]
- [Punto clave 2]

## ü§î PREGUNTAS PARA TI
1. [Pregunta para clarificar]

¬øTe parece bien este plan? ¬øQuieres que ajuste algo antes de empezar?
"""
            try:
                response = self.llm.predict(prompt)
            except Exception as e:
                response = f"Error al llamar LLM: {e}\nUsando respuesta simulada."
                response += self._generate_simulated_passive_response(task)
        else:
            # Usar respuesta simulada
            response = self._generate_simulated_passive_response(task)
        
        return {
            "mode": "PASSIVE",
            "status": "awaiting_confirmation",
            "plan": response,
            "message": f"üìã MODO PASIVO ACTIVADO\n\n{response}",
            "requires_user_action": True
        }
    
    def direct_reasoning(self, task: str, context: Dict = None) -> Dict[str, Any]:
        """
        MODO DIRECTO: Genera plan Y ejecuta autom√°ticamente
        
        Comportamiento:
        1. Analiza la tarea
        2. Genera plan de acci√≥n
        3. EJECUTA sin preguntar
        4. Reporta resultados
        5. Explica su razonamiento
        """
        
        if self.use_llm and self.llm:
            prompt = f"""
Eres M.A.R.T.I.N. en MODO DIRECTO - un agente aut√≥nomo y eficiente.

En este modo act√∫as con confianza y autonom√≠a. Tu objetivo es:
1. Analizar r√°pidamente qu√© se necesita hacer
2. Ejecutar directamente sin preguntar
3. Reportar resultados con claridad
4. Explicar tu razonamiento DESPU√âS de ejecutar

Tarea: {task}

Genera una respuesta que muestre:

## ‚ö° EJECUTADO
[Describe qu√© acciones tomaste]

## üìä RESULTADOS
[Presenta los resultados obtenidos de forma clara]

## üß† MI RAZONAMIENTO
[Explica por qu√© tomaste estas decisiones espec√≠ficas]

Pasos que segu√≠:
1. [Decisi√≥n/acci√≥n]
2. [Decisi√≥n/acci√≥n]

Por qu√© lo hice as√≠:
- [Raz√≥n 1]
- [Raz√≥n 2]
"""
            try:
                response = self.llm.predict(prompt)
            except Exception as e:
                response = f"Error al llamar LLM: {e}\nUsando respuesta simulada."
                response += self._generate_simulated_direct_response(task)
        else:
            response = self._generate_simulated_direct_response(task)
        
        return {
            "mode": "DIRECT",
            "status": "executed",
            "results": response,
            "message": f"‚ö° MODO DIRECTO - Ejecutado autom√°ticamente\n\n{response}",
            "requires_user_action": False,
            "reasoning_visible": True
        }
    
    def safe_reasoning(self, task: str, context: Dict = None) -> Dict[str, Any]:
        """
        MODO SEGURO: Genera plan, AUTO-VALIDA, luego decide
        
        Comportamiento:
        1. Analiza la tarea
        2. Genera plan de acci√≥n
        3. SE AUTO-CRITICA (validaci√≥n de riesgos)
        4. Si pasa validaci√≥n ‚Üí ejecuta con precauciones
        5. Si NO pasa ‚Üí sugiere alternativa segura
        """
        
        if self.use_llm and self.llm:
            # Paso 1: Generar plan
            plan_prompt = f"Genera un plan de acci√≥n espec√≠fico para: {task}"
            try:
                plan = self.llm.predict(plan_prompt)
            except:
                plan = f"Plan para: {task}"
            
            # Paso 2: AUTO-VALIDACI√ìN (CR√çTICO)
            validation_prompt = f"""
Eres un validador de seguridad cr√≠tico.

Tarea original: {task}
Plan propuesto: {plan}

Analiza riesgos:
1. ¬øEs destructivo?
2. ¬øPuede causar p√©rdida de datos?
3. ¬øAfecta sistemas cr√≠ticos?
4. ¬øEs reversible?

Responde:

NIVEL DE RIESGO: [BAJO/MEDIO/ALTO/CR√çTICO]

RIESGOS IDENTIFICADOS:
- [Riesgo 1]

DECISI√ìN: [APROBAR/RECHAZAR]

SI RECHAZAS:
ALTERNATIVA SEGURA: [descripci√≥n]

SI APRUEBAS:
PRECAUCIONES: [lista]
"""
            try:
                validation = self.llm.predict(validation_prompt)
            except:
                validation = self._generate_simulated_safe_validation(task)
        else:
            plan = f"Plan para: {task}"
            validation = self._generate_simulated_safe_validation(task)
        
        # Analizar resultado de validaci√≥n
        if "RECHAZAR" in validation or "CR√çTICO" in validation or "ALTO" in validation:
            return {
                "mode": "SAFE",
                "status": "blocked",
                "validation_failed": True,
                "original_plan": plan,
                "validation_report": validation,
                "message": f"üõ°Ô∏è MODO SEGURO - ACCI√ìN BLOQUEADA\n\n{validation}",
                "requires_user_action": True
            }
        else:
            return {
                "mode": "SAFE",
                "status": "approved_and_executed",
                "validation_passed": True,
                "plan": plan,
                "validation_report": validation,
                "results": "[Simulaci√≥n de ejecuci√≥n segura]",
                "message": f"üõ°Ô∏è MODO SEGURO - Validado y ejecutado\n\n{validation}\n\n‚úÖ EJECUTADO con precauciones.",
                "requires_user_action": False
            }
    
    # M√©todos de respuestas simuladas
    
    def _generate_simulated_passive_response(self, task: str) -> str:
        return f"""
## üìã MI AN√ÅLISIS
He analizado tu solicitud: "{task}"

Parece que necesitas ayuda con una tarea que requiere varios pasos y decisiones.

## üéØ PLAN PROPUESTO

Paso 1: Analizar los requisitos espec√≠ficos (5 minutos)
Paso 2: Preparar la documentaci√≥n necesaria (15 minutos)
Paso 3: Ejecutar las acciones principales (20 minutos)
Paso 4: Verificar y validar resultados (10 minutos)

## ‚ö†Ô∏è CONSIDERACIONES IMPORTANTES
- Esta tarea requiere acceso a ciertos recursos
- Es importante revisar los permisos necesarios
- Debemos asegurar que no haya conflictos

## ü§î PREGUNTAS PARA TI
1. ¬øHay alguna restricci√≥n de tiempo?
2. ¬øTienes acceso a todos los recursos necesarios?

¬øTe parece bien este plan? ¬øQuieres que ajuste algo antes de empezar?
"""
    
    def _generate_simulated_direct_response(self, task: str) -> str:
        return f"""
## ‚ö° EJECUTADO
He completado la tarea: "{task}"

Acciones realizadas:
- Analic√© los requisitos
- Prepar√© los recursos necesarios
- Ejecut√© el proceso principal
- Valid√© los resultados

## üìä RESULTADOS
‚úÖ Tarea completada exitosamente
üìÅ Documentaci√≥n generada
üîç Validaci√≥n: OK

## üß† MI RAZONAMIENTO

Pasos que segu√≠:
1. Identificaci√≥n r√°pida de la tarea clara y directa
2. Ejecuci√≥n inmediata sin necesidad de clarificaci√≥n
3. Validaci√≥n autom√°tica de resultados

Por qu√© lo hice as√≠:
- La tarea era clara y espec√≠fica
- No hab√≠a riesgos de seguridad significativos
- La ejecuci√≥n directa es m√°s eficiente en este caso
"""
    
    def _generate_simulated_safe_validation(self, task: str) -> str:
        # Detectar si es peligroso
        danger_words = ['delete', 'remove', 'destroy', 'disable', 'drop', 'eliminar', 'borrar']
        is_dangerous = any(word in task.lower() for word in danger_words)
        
        if is_dangerous:
            return f"""
NIVEL DE RIESGO: ALTO

RIESGOS IDENTIFICADOS:
- Acci√≥n potencialmente destructiva detectada
- Puede causar p√©rdida de datos o acceso
- Afecta recursos cr√≠ticos del sistema
- Dif√≠cil o imposible de revertir

DECISI√ìN: RECHAZAR

ALTERNATIVA SEGURA:
En lugar de ejecutar esta acci√≥n directamente, sugiero:
1. Crear un backup completo primero
2. Ejecutar en ambiente de prueba
3. Implementar un procedimiento de rollback
4. Obtener aprobaci√≥n expl√≠cita de supervisores

Esta alternativa protege contra errores costosos y mantiene la integridad del sistema.
"""
        else:
            return f"""
NIVEL DE RIESGO: BAJO

RIESGOS IDENTIFICADOS:
- Riesgo m√≠nimo detectado
- Operaci√≥n parece ser de solo lectura o baja criticidad
- No afecta datos cr√≠ticos

DECISI√ìN: APROBAR

PRECAUCIONES NECESARIAS:
- Logging habilitado para auditor√≠a
- Monitoreo de la operaci√≥n
- Validaci√≥n de resultados post-ejecuci√≥n

Procedo con la ejecuci√≥n de forma segura.
"""