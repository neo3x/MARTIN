"""
Interfaz de usuario con Gradio para M.A.R.T.I.N.
Con soporte para m√∫ltiples LLMs (OpenAI y Claude)
"""
import sys
import os
from pathlib import Path

# ‚úÖ IMPORTAR GRADIO PRIMERO
import gradio as gr
from dotenv import load_dotenv

# DEBUG: Verificar que gradio funciona AQU√ç
print(f"DEBUG 1: Gradio tiene Blocks ANTES de importar MARTINAgent: {hasattr(gr, 'Blocks')}")
print(f"DEBUG 1: Gradio location: {gr.__file__}")

# ‚úÖ Cargar .env temprano
load_dotenv()

# ‚úÖ AHORA modificar path
root_dir = Path(__file__).parent.parent
sys.path.insert(0, str(root_dir))

# ‚úÖ Importar lo que necesita el path modificado
from agent_core.martin_agent import MARTINAgent

# DEBUG: Verificar que gradio funciona DESPU√âS
print(f"DEBUG 2: Gradio tiene Blocks DESPU√âS de importar MARTINAgent: {hasattr(gr, 'Blocks')}")

# Si cambi√≥, MARTINAgent est√° corrompiendo el import
if not hasattr(gr, 'Blocks'):
    print("üî¥ ERROR: MARTINAgent corrompi√≥ el import de gradio!")
    print(f"üî¥ Gradio ahora es: {gr}")
    print(f"üî¥ Gradio.__file__: {gr.__file__ if hasattr(gr, '__file__') else 'NO TIENE __file__'}")
class MARTINInterface:
    def __init__(self, llm_provider="auto"):
        """
        Args:
            llm_provider: "openai", "claude", o "auto"
        """
        # Detectar API keys disponibles
        self.has_openai = os.getenv('OPENAI_API_KEY') is not None
        self.has_claude = os.getenv('ANTHROPIC_API_KEY') is not None
        
        use_llm = self.has_openai or self.has_claude
        
        self.agent = MARTINAgent(
            use_llm=use_llm,
            llm_provider=llm_provider,
            verbose=False
        )
        self.conversation = []
        
        # Mostrar estado inicial
        if use_llm:
            if self.agent.llm_provider == "openai":
                print("‚úÖ Usando OpenAI GPT-4")
            elif self.agent.llm_provider == "claude":
                print("‚úÖ Usando Anthropic Claude 3.5 Sonnet")
        else:
            print("‚ö†Ô∏è  Sin API Keys - Usando modo simulado")
            print("   Para usar LLMs reales, configura API keys en .env")
    
    def switch_llm(self, provider):
        """Cambia el proveedor de LLM"""
        
        # Verificar que tenga la API key necesaria
        if provider == "openai" and not self.has_openai:
            return "‚ùå OPENAI_API_KEY no configurada en .env"
        
        if provider == "claude" and not self.has_claude:
            return "‚ùå ANTHROPIC_API_KEY no configurada en .env"
        
        # Reiniciar agente con nuevo proveedor
        self.agent = MARTINAgent(
            use_llm=True,
            llm_provider=provider,
            verbose=False
        )
        
        provider_names = {
            "openai": "OpenAI GPT-4",
            "claude": "Anthropic Claude 3.5 Sonnet"
        }
        
        return f"‚úÖ Cambiado a {provider_names.get(provider, provider)}"
    
    def process_message(self, message, environment, history):
        """Procesa mensaje del usuario"""
        
        if not message.strip():
            return history, "", "Por favor ingresa un mensaje"
        
        context = {
            'environment': environment
        }
        
        # Procesar con M.A.R.T.I.N.
        result = self.agent.process(message, context)
        
        # Formatear respuesta
        response = self._format_response(result)
        mode_info = self._format_mode_info(result)
        
        # Agregar a historial
        history.append((message, response))
        
        return history, "", mode_info
    
    def _format_response(self, result):
        """Formatea la respuesta de M.A.R.T.I.N. para mostrar en UI"""
        
        mode_emoji = {
            'PASSIVE': 'üü¶',
            'DIRECT': 'üü©',
            'SAFE': 'üü®'
        }
        
        emoji = mode_emoji.get(result['mode'], '‚ö™')
        
        response = f"{emoji} **Modo {result['mode']} activado**\n\n"
        response += result['message']
        
        if result.get('requires_user_action'):
            response += "\n\n‚ö†Ô∏è *Esperando tu confirmaci√≥n para continuar*"
        
        return response
    
    def _format_mode_info(self, result):
        """Muestra informaci√≥n sobre por qu√© se eligi√≥ ese modo"""
        return result.get('mode_explanation', 'No hay explicaci√≥n disponible')
    
    def reset_conversation(self):
        """Reinicia la conversaci√≥n"""
        self.agent.reset()
        return [], "‚úÖ Conversaci√≥n reiniciada"
    
    def export_conversation(self):
        """Exporta la conversaci√≥n"""
        filepath = self.agent.export_conversation()
        return f"‚úÖ Conversaci√≥n exportada a: {filepath}"
    
    def get_stats(self):
        """Obtiene estad√≠sticas"""
        stats = self.agent.get_stats()
        llm_info = {
            "openai": "OpenAI GPT-4",
            "claude": "Anthropic Claude 3.5 Sonnet",
            "simulado": "Modo simulado (sin API key)"
        }.get(stats['llm_provider'], stats['llm_provider'])
        
        return f"""
üìä ESTAD√çSTICAS DE LA SESI√ìN

Total de interacciones: {stats['total_interactions']}
Modos usados: {stats['modes_used']}
Session ID: {stats['session_id']}
LLM: {llm_info}
"""
    
    def create_interface(self):
        """Crea la interfaz Gradio con selector de LLM"""
        
        with gr.Blocks(
            title="M.A.R.T.I.N. Agent",
            theme=gr.themes.Soft()
        ) as interface:
            
            gr.Markdown("""
            # üß† M.A.R.T.I.N.
            ## Modular Assistant for Reasoning, Tactics, Inference and Navigation
            
            Agente de IA con **razonamiento tri-modal adaptativo** para compliance automation
            """)
            
            # Selector de LLM (solo si hay al menos una API key)
            if self.has_openai or self.has_claude:
                with gr.Row():
                    gr.Markdown("### ü§ñ Seleccionar LLM:")
                    
                    llm_choices = []
                    if self.has_openai:
                        llm_choices.append(("GPT-4 (OpenAI)", "openai"))
                    if self.has_claude:
                        llm_choices.append(("Claude 3.5 (Anthropic)", "claude"))
                    
                    llm_selector = gr.Radio(
                        choices=llm_choices,
                        value=llm_choices[0][1] if llm_choices else None,
                        label="Proveedor de LLM",
                        info="Puedes cambiar entre modelos durante la conversaci√≥n"
                    )
                    
                    current_llm = "GPT-4" if self.agent.llm_provider == "openai" else "Claude 3.5" if self.agent.llm_provider == "claude" else "Simulado"
                    
                    llm_status = gr.Textbox(
                        label="Estado actual",
                        value=f"‚úÖ Usando {current_llm}",
                        interactive=False,
                        lines=1
                    )
            else:
                gr.Markdown("""
                ‚ö†Ô∏è **Sin API Keys configuradas** - Ejecutando en modo simulado
                
                Para usar LLMs reales:
                1. Copia `.env.example` a `.env`
                2. Agrega tu `OPENAI_API_KEY` o `ANTHROPIC_API_KEY`
                3. Reinicia la aplicaci√≥n
                """)
            
            with gr.Row():
                with gr.Column(scale=2):
                    chatbot = gr.Chatbot(
                        label="Conversaci√≥n con M.A.R.T.I.N.",
                        height=500,
                        show_label=True
                    )
                    
                    with gr.Row():
                        msg_input = gr.Textbox(
                            label="Tu mensaje",
                            placeholder="Ej: Ay√∫dame a preparar mi startup para SOC 2",
                            lines=2,
                            show_label=False
                        )
                    
                    with gr.Row():
                        submit_btn = gr.Button("Enviar", variant="primary", scale=2)
                        clear_btn = gr.Button("Limpiar", scale=1)
                    
                    with gr.Row():
                        environment = gr.Radio(
                            choices=["development", "staging", "production"],
                            value="development",
                            label="üåç Ambiente",
                            info="El ambiente afecta c√≥mo M.A.R.T.I.N. razona"
                        )
                
                with gr.Column(scale=1):
                    mode_info = gr.Textbox(
                        label="üß† Razonamiento de M.A.R.T.I.N.",
                        lines=15,
                        max_lines=25,
                        show_label=True,
                        interactive=False
                    )
                    
                    gr.Markdown("""
                    ### Modos de Razonamiento:
                    
                    üü¶ **PASIVO**: Propone plan, espera confirmaci√≥n  
                    *Uso: Tareas ambiguas, exploraci√≥n*
                    
                    üü© **DIRECTO**: Ejecuta aut√≥nomamente  
                    *Uso: Tareas claras, bajo riesgo*
                    
                    üü® **SEGURO**: Auto-valida antes de actuar  
                    *Uso: Alto riesgo, producci√≥n*
                    """)
                    
                    with gr.Row():
                        export_btn = gr.Button("üìÅ Exportar", scale=1)
                        stats_btn = gr.Button("üìä Stats", scale=1)
                    
                    output_info = gr.Textbox(
                        label="Informaci√≥n",
                        lines=4,
                        show_label=False,
                        interactive=False
                    )
            
            gr.Markdown("""
            ---
            ### üí° Ejemplos de queries:
            
            **Modo Pasivo:**
            - "Ay√∫dame a preparar compliance para SOC 2"
            - "¬øC√≥mo configuro mi firewall para seguridad?"
            
            **Modo Directo:**
            - "Genera pol√≠tica de contrase√±as seg√∫n ISO 27001"
            - "Crea un checklist de onboarding de empleados"
            
            **Modo Seguro:**
            - "Deshabilita usuario admin@empresa.com" (en producci√≥n)
            - "Elimina todos los logs antiguos"
            """)
            
            # Event handlers
            def submit(message, env, history):
                new_history, cleared_input, mode_explanation = self.process_message(
                    message, env, history
                )
                return new_history, cleared_input, mode_explanation
            
            submit_btn.click(
                submit,
                inputs=[msg_input, environment, chatbot],
                outputs=[chatbot, msg_input, mode_info]
            )
            
            msg_input.submit(
                submit,
                inputs=[msg_input, environment, chatbot],
                outputs=[chatbot, msg_input, mode_info]
            )
            
            clear_btn.click(
                lambda: self.reset_conversation(),
                outputs=[chatbot, output_info]
            )
            
            export_btn.click(
                lambda: self.export_conversation(),
                outputs=[output_info]
            )
            
            stats_btn.click(
                lambda: self.get_stats(),
                outputs=[output_info]
            )
            
            # Event handler para cambio de LLM
            if self.has_openai or self.has_claude:
                llm_selector.change(
                    self.switch_llm,
                    inputs=[llm_selector],
                    outputs=[llm_status]
                )
        
        return interface


def main():
    """Funci√≥n principal"""
    print("="*60)
    print("üß† M.A.R.T.I.N. - Interfaz Gradio")
    print("="*60)
    
    # Detectar LLM provider desde .env o auto
    llm_provider = os.getenv('LLM_PROVIDER', 'auto')
    
    ui = MARTINInterface(llm_provider=llm_provider)
    interface = ui.create_interface()
    
    print("\nüöÄ Lanzando interfaz web...")
    print("üìç Una vez iniciada, abre el navegador en la URL que aparece")
    
    if ui.has_openai or ui.has_claude:
        print("\n‚úÖ API Keys detectadas:")
        if ui.has_openai:
            print("   ‚Ä¢ OpenAI GPT-4")
        if ui.has_claude:
            print("   ‚Ä¢ Anthropic Claude 3.5 Sonnet")
        print("\nüí° Puedes cambiar entre modelos desde la interfaz")
    else:
        print("\n‚ö†Ô∏è  Ejecutando en modo simulado")
        print("   Para usar LLMs reales, configura tu API key en .env")
    
    print()
    
    interface.launch(
        share=False,
        server_name="0.0.0.0",
        server_port=7860
    )


if __name__ == "__main__":
    main()